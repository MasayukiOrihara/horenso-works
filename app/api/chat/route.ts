import { LangSmithClient } from "@/lib/clients";
import * as MESSAGES from "@/lib/messages";
import { OpenAi } from "@/lib/models";
import { PromptTemplate } from "@langchain/core/prompts";
import { LangChainAdapter } from "ai";

import { formatMessage, getBaseUrl, logMessage } from "./utils";
import {
  AIMessage,
  BaseMessage,
  ChatMessage,
  HumanMessage,
} from "@langchain/core/messages";

// å¤–éƒ¨ãƒ•ãƒ©ã‚°
let horensoContenue = false;
let oldHorensoContenue = false;

/**
 * å ±é€£ç›¸ãƒ¯ãƒ¼ã‚¯AI
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const { host, baseUrl } = getBaseUrl(req);
    const getBoolHeader = (key: string) => req.headers.get(key) === "true";

    let step = "0";

    // éå»ã®å±¥æ­´
    const formattedPreviousMessages = messages.slice(0, -1).map(formatMessage);
    // ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    const userMessage = messages[messages.length - 1].content;

    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰è¨˜æ†¶è¨­å®šã‚’å–å¾—
    const humanMessage = new HumanMessage(userMessage);
    if (getBoolHeader("memoryOn")) {
      await logMessage(host, humanMessage);
    }

    // æŒ‡æ‘˜ã®å–å¾—: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰æŒ‡æ‘˜è¨­å®šã‚’å–å¾—
    // â€»â€»â€» ãŸã¶ã‚“ã¾ã å‹•ãã¾ã›ã‚“
    if (getBoolHeader("learnOn")) {
      await logMessage(host, userMessage);
    }

    // ãƒ‡ãƒãƒƒã‚¯: åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¹ã‚­ãƒƒãƒ—
    if (getBoolHeader("debug")) {
      console.log("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ä½œå‹•ä¸­...");
      step = req.headers.get("step") ?? "0";
    }

    // å§‹å‹•æ™‚ã®çŠ¶æ…‹åˆ¤å®š
    let aiMessage = "";
    horensoContenue = true;
    if (horensoContenue && !oldHorensoContenue && !getBoolHeader("debug")) {
      // åˆå›AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      oldHorensoContenue = true;

      aiMessage =
        MESSAGES.DEVELOPMENT_WORK_EXPLANATION + MESSAGES.QUESTION_WHO_ASKING;
      console.log("ğŸ å§‹ã‚ã®ä¼šè©±");
    } else {
      // å ±é€£ç›¸ãƒ¯ãƒ¼ã‚¯APIå‘¼ã³å‡ºã—
      const res = await fetch(baseUrl + "/api/horenso", {
        method: "POST",
        credentials: "include",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${process.env.ACCESS_TOKEN}`,
          step: step,
        },
        body: JSON.stringify({ messages }),
      });
      const apiBody = await res.json();
      aiMessage = apiBody.text;

      // çµ‚äº†æ™‚ã®çŠ¶æ…‹åˆ¤å®š
      console.log("ç¶™ç¶šåˆ¤å®š apiå´: " + apiBody.contenue);
      console.log("ç¶™ç¶šåˆ¤å®š chatå´: " + horensoContenue);
      if (apiBody.contenue != horensoContenue) {
        horensoContenue = false;
        aiMessage = aiMessage + "\n\n" + MESSAGES.FINISH_MESSAGE;
      }
    }

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’å–å¾—ã—ã¦è¡¨ç¤º
    const promptVariables = {
      chat_history: formattedPreviousMessages,
      user_message: userMessage,
      ai_message: aiMessage,
    };

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿
    const load = await LangSmithClient.pullPromptCommit("horenso_ai-kato");
    const template = load.manifest.kwargs.template;
    const prompt = PromptTemplate.fromTemplate(template);

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
    const stream = await prompt.pipe(OpenAi).stream({
      chat_history: formattedPreviousMessages,
      user_message: userMessage,
      ai_message: aiMessage,
    });

    const fullPrompt = await prompt.format(promptVariables);
    console.log("=== é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ ===");
    console.log(fullPrompt);
    console.log("================================");

    // ReadableStream ã‚’æ‹¡å¼µã—ã¦çµ‚äº†æ¤œçŸ¥
    const enhancedStream = new ReadableStream({
      async start(controller) {
        let fullText = "";

        for await (const chunk of stream) {
          fullText += chunk.content || "";

          // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«ã¯ãã®ã¾ã¾æµã™
          controller.enqueue(chunk);
        }
        console.log("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ‚äº†");

        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰è¨˜æ†¶è¨­å®šã‚’å–å¾—
        const aiMessage = new AIMessage(fullText);
        if (getBoolHeader("memoryOn")) {
          await logMessage(host, aiMessage);
        }
        controller.close();
      },
    });

    return LangChainAdapter.toDataStreamResponse(enhancedStream);
  } catch (error) {
    console.log(error);
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
