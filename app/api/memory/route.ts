import { haiku3_5_sentence, openAi4oMini } from "@/lib/models";
import { RemoveMessage, SystemMessage } from "@langchain/core/messages";
import {
  Annotation,
  END,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

/** ä¼šè©±ã‚’è¡Œã†ã‹è¦ç´„ã™ã‚‹ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldContenue(state: typeof GraphAnnotation.State) {
  console.log("â“ should contenue");
  const messages = state.messages;

  if (messages.length > 3) return "summarize";
  return END;
}

/** ä¼šè©±ã®è¦ç´„å‡¦ç† */
async function summarizeConversation(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“ƒ summarize conversation");
  const summary = state.summary;

  let summaryMessage;
  if (summary) {
    summaryMessage = `Conversation summary so far: ${summary}\n\nä¸Šè¨˜ã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ã¦è¦ç´„ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚: `;
  } else {
    summaryMessage =
      "ä¸Šè¨˜ã®å…¥åŠ›ã‚’éå»ã®ä¼šè©±ã®è¨˜æ†¶ã¨ã—ã¦ä¿æŒã§ãã‚‹ã‚ˆã†ã«é‡è¦ãªæ„å›³ã‚„æƒ…å ±ãƒ»æµã‚ŒãŒã‚ã‹ã‚‹ã‚ˆã†ã«çŸ­ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚: ";
  }

  // è¦ç´„å‡¦ç†
  const messages = [...state.messages, new SystemMessage(summaryMessage)];
  const response = await openAi4oMini.invoke(messages);
  console.log(response.content);

  const deleteMessages = messages
    .slice(0, -2)
    .map((m) => new RemoveMessage({ id: m.id! }));
  return { summary: response.content, messages: deleteMessages };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  summary: Annotation<string>(),
  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("summarize", summarizeConversation)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addConditionalEdges("__start__", shouldContenue)
  .addEdge("summarize", END);

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const currentMessage = messages[messages.length - 1].content;

    const config = { configurable: { thread_id: "abc123" } };
    const results = await app.invoke({ messages: currentMessage }, config);

    const conversation = [];
    for (let message of results.messages) {
      const typeId = message?.id?.[2]; // ['langchain_core', 'messages', 'HumanMessage'] ã®3ã¤ç›®

      if (typeId === "HumanMessage")
        conversation.push(`user: ${message.content}`);
      if (typeId === "AIMessage")
        conversation.push(`assistant: ${message.content}`);

      conversation.push(`system: ${message.content}`);
    }

    return new Response(JSON.stringify(conversation), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
