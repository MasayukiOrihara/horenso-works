import { RemoveMessage, SystemMessage } from "@langchain/core/messages";
import {
  Annotation,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

import { openAi4oMini } from "@/lib/models";

// ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: è‹±èªã«ã—ã¦ç¯€ç´„ã—ã¦ã¿ã‚‹ (æ³¨) ã‚‚ã—è‹±èªã§å›ç­”ã—ã ã™ç”¨ãªã‚‰æˆ»ã™
/* åŸæ–‡ `Conversation summary so far: ${summary}\n\nä¸Šè¨˜ã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ã¦è¦ç´„ã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚: ` */
const MEMORY_UPDATE_PROMPT =
  "Here is the conversation summary so far: {summary}\n\nBased on the new message above, expand this summary while retaining important intent, information, and conversational flow for long-term memory.";
/* åŸæ–‡ "ä¸Šè¨˜ã®å…¥åŠ›ã‚’éå»ã®ä¼šè©±ã®è¨˜æ†¶ã¨ã—ã¦ä¿æŒã§ãã‚‹ã‚ˆã†ã«é‡è¦ãªæ„å›³ã‚„æƒ…å ±ãƒ»æµã‚ŒãŒã‚ã‹ã‚‹ã‚ˆã†ã«çŸ­ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚: " */
const MEMORY_SUMMARY_PROMPT =
  "Summarize the input above concisely to preserve its key intent, information, and conversational flow, so it can be stored as memory for future context.";

/** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ¿å…¥ã™ã‚‹å‡¦ç† */
async function insartMessages(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“© insart messages");

  const messages = state.messages;
  return { messages: messages };
}

/** è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹å‡¦ç† */
async function prepareMessages(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“§ prepare messages");

  const summary = state.summary;
  // è¦ç´„ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
  const systemMessage = `Previous conversation summary: ${summary}`;
  const messages = [new SystemMessage(systemMessage)];

  return { messages: messages };
}

/** ä¼šè©±ã‚’è¡Œã†ã‹è¦ç´„ã™ã‚‹ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldContenue(state: typeof GraphAnnotation.State) {
  console.log("â“ should contenue");
  const messages = state.messages;

  if (messages.length > 6) return "summarize";
  return "__end__";
}

/** ä¼šè©±ã®è¦ç´„å‡¦ç† */
async function summarizeConversation(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“ƒ summarize conversation");
  const summary = state.summary;

  let summaryMessage;

  if (summary) {
    summaryMessage = MEMORY_UPDATE_PROMPT.replace("{summary}", summary);
  } else {
    summaryMessage = MEMORY_SUMMARY_PROMPT;
  }

  // è¦ç´„å‡¦ç†
  const messages = [...state.messages, new SystemMessage(summaryMessage)];
  const response = await openAi4oMini.invoke(messages);

  // è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é™¤å»
  const deleteMessages = messages
    .slice(0, -2)
    .map((m) => new RemoveMessage({ id: m.id! }));
  return { summary: response.content, messages: deleteMessages };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  summary: Annotation<string>(),
  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("insart", insartMessages)
  .addNode("prepare", prepareMessages)
  .addNode("summarize", summarizeConversation)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addEdge("__start__", "insart")
  .addConditionalEdges("insart", shouldContenue)
  .addEdge("summarize", "prepare")
  .addEdge("prepare", "__end__");

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];

    // 2è¡Œå–å¾—
    const len = messages.length;
    const previousMessage = messages.slice(Math.max(0, len - 2), len);

    // å±¥æ­´ç”¨ã‚­ãƒ¼
    const config = { configurable: { thread_id: "abc123" } };
    const results = await app.invoke({ messages: previousMessage }, config);

    // å±¥æ­´ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åŠ å·¥
    const conversation = [];
    for (let message of results.messages) {
      const content = String(message.content).replace(/\r?\n/g, "");

      switch (message.getType()) {
        case "human":
          conversation.push(`user: ${content}`);
          break;
        case "ai":
          conversation.push(`assistant: ${content}`);
          break;
        default:
          conversation.push(`${content}`);
      }
    }

    return new Response(JSON.stringify(conversation), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
