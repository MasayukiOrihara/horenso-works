import { RemoveMessage } from "@langchain/core/messages";
import { PromptTemplate } from "@langchain/core/prompts";
import {
  Annotation,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

import { strParser } from "@/lib/llm/models";
import { convertToOpenAIFormat } from "../../utils";
import { runWithFallback } from "@/lib/llm/run";
import { measureExecution } from "@/lib/llm/graph";
import * as MSG from "@/lib/contents/memory/template";
import * as ERR from "@/lib/message/error";

// å®šæ•°
const MAX_LENGTH = 6; // è¦ç´„ã‚’ã™ã‚‹æœ€å¤§è¡Œ
const MAX_CHAR_LENGTH = 40; // è¦ç´„ã™ã‚‹æœ€å¤§æ–‡å­—æ•°

/** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ¿å…¥ã™ã‚‹å‡¦ç† */
async function insartMessages(state: typeof GraphAnnotation.State) {
  const messages = state.messages;

  return { messages: messages };
}

/** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹å‡¦ç† */
async function convertFormat(state: typeof GraphAnnotation.State) {
  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—
  const messages = state.messages;
  const formatted = state.formatted ?? [];

  const sessionId = state.sessionId;

  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é¸æŠ
  const len = state.messages.length;
  const previousMessage = state.messages.slice(Math.max(0, len - 2), len);

  // message ã‚’æ•´å½¢
  for (const message of previousMessage) {
    const openaiFormat = convertToOpenAIFormat(message);

    // assistant ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é•·ã„ã®ã§æ¯å›è¦ç´„
    const role = openaiFormat.role;
    let content = openaiFormat.content;
    try {
      if (role === "assistant" && content.length > MAX_CHAR_LENGTH) {
        const prompt = PromptTemplate.fromTemplate(MSG.SUMMARY_PROMPT);
        const summary = await runWithFallback(
          prompt,
          { input: content },
          {
            mode: "invoke",
            parser: strParser,
            label: "assistant summary",
            sessionId: sessionId,
          }
        );
        content = summary.content;
      }
    } catch (error) {
      console.warn(`${ERR.SUMMARY_ERROR}: ${error} `);
    }
    const stringFormat = `${role}: ${content}`;
    const cleanFormat = stringFormat.replace(/[\r\n]+/g, "");
    formatted.push(cleanFormat);
  }

  // è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é™¤å»
  const deleteMessages = messages
    .slice(0, -2)
    .map((m) => new RemoveMessage({ id: m.id! }));

  return { formatted: formatted, messages: deleteMessages };
}

/** ä¼šè©±ã‚’è¡Œã†ã‹è¦ç´„ã™ã‚‹ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldContenue(state: typeof GraphAnnotation.State) {
  const formatted = state.formatted;

  if (formatted.length > MAX_LENGTH) return "summarize";
  return "__end__";
}

/** ä¼šè©±ã®è¦ç´„å‡¦ç† */
async function summarizeConversation(state: typeof GraphAnnotation.State) {
  const summary = state.summary;
  const formatted = state.formatted;
  const formattedText = formatted.join("\n");
  const sessionId = state.sessionId;

  // è¦ç´„ã®æœ‰ç„¡ã«ã‚ˆã£ã¦åˆ†å²
  let summaryMessage = MSG.SUMMARY_PROMPT;
  type PromptVariables = {
    input: string;
    summary?: string;
  };
  let promptVariables: PromptVariables = { input: formattedText };
  if (summary) {
    summaryMessage = MSG.MEMORY_UPDATE_PROMPT;
    promptVariables = { input: formattedText, summary: summary };
  }

  // è¦ç´„å‡¦ç†
  let responseSummary = "";
  // è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é™¤å»
  let empty: string[] = [];
  try {
    const prompt = PromptTemplate.fromTemplate(summaryMessage);
    const response = await runWithFallback(prompt, promptVariables, {
      mode: "invoke",
      parser: strParser,
      label: "memory summary",
      sessionId: sessionId,
    });
    responseSummary = response.content;
  } catch (error) {
    console.warn(`${ERR.SUMMARY_ERROR}: ${error}`);
    empty = [...formatted];
  }

  return { summary: responseSummary, formatted: empty };
}

/** è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹å‡¦ç† */
async function prepareMessages(state: typeof GraphAnnotation.State) {
  const formatted = state.formatted ?? [];

  const summary = state.summary;
  // è¦ç´„ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
  const systemMessage = `Previous conversation summary: ${summary}`;
  formatted.push(systemMessage);

  return { formatted: formatted };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  summary: Annotation<string>(),
  formatted: Annotation<string[]>(),
  sessionId: Annotation<string>(),
  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("insart", insartMessages)
  .addNode("format", convertFormat)
  .addNode("prepare", prepareMessages)
  .addNode("summarize", summarizeConversation)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addEdge("__start__", "insart")
  .addEdge("insart", "format")
  .addConditionalEdges("format", shouldContenue)
  .addEdge("summarize", "prepare")
  .addEdge("prepare", "__end__");

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const sessionId = body.sessionId;
    if (!sessionId) {
      console.error("ğŸ’¿ memory API POST error: " + ERR.SESSIONID_ERROR);
      return Response.json({ error: ERR.SESSIONID_ERROR }, { status: 400 });
    }

    // 2è¡Œå–å¾—
    const len = messages.length;
    const previousMessage = messages.slice(Math.max(0, len - 2), len);

    // å±¥æ­´ç”¨ã‚­ãƒ¼
    const config = { configurable: { thread_id: sessionId } };

    // å®Ÿè¡Œ
    const results = await measureExecution(
      app,
      "memory",
      { messages: previousMessage, sessionId },
      config
    );

    return Response.json(results.formatted, { status: 200 });
  } catch (error) {
    const message = error instanceof Error ? error.message : ERR.UNKNOWN_ERROR;

    console.error("ğŸ’¿ memory API POST error: " + message);
    return Response.json({ error: message }, { status: 500 });
  }
}
